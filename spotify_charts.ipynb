{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieves list of songs from SpotifyCharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fycharts.SpotifyCharts import SpotifyCharts\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 10/03/2020 02:32:40 PM : Extracting top 200 daily for 2017-01-01 - us\n",
      "INFO : 10/03/2020 02:32:41 PM : Extracting top 200 daily for 2017-01-02 - us\n",
      "INFO : 10/03/2020 02:32:41 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:41 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:42 PM : Extracting top 200 daily for 2017-01-03 - us\n",
      "INFO : 10/03/2020 02:32:42 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:42 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:43 PM : Extracting top 200 daily for 2017-01-04 - us\n",
      "INFO : 10/03/2020 02:32:43 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:43 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:44 PM : Extracting top 200 daily for 2017-01-05 - us\n",
      "INFO : 10/03/2020 02:32:44 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:44 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:44 PM : Extracting top 200 daily for 2017-01-06 - us\n",
      "INFO : 10/03/2020 02:32:44 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:44 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:46 PM : Extracting top 200 daily for 2017-01-07 - us\n",
      "INFO : 10/03/2020 02:32:46 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:46 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:46 PM : Extracting top 200 daily for 2017-01-08 - us\n",
      "INFO : 10/03/2020 02:32:46 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:46 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:47 PM : Extracting top 200 daily for 2017-01-09 - us\n",
      "INFO : 10/03/2020 02:32:47 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:47 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:48 PM : Extracting top 200 daily for 2017-01-10 - us\n",
      "INFO : 10/03/2020 02:32:48 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:48 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:49 PM : Extracting top 200 daily for 2017-01-11 - us\n",
      "INFO : 10/03/2020 02:32:49 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:49 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:50 PM : Extracting top 200 daily for 2017-01-12 - us\n",
      "INFO : 10/03/2020 02:32:50 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:50 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:52 PM : Extracting top 200 daily for 2017-01-13 - us\n",
      "INFO : 10/03/2020 02:32:52 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:52 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:53 PM : Extracting top 200 daily for 2017-01-14 - us\n",
      "INFO : 10/03/2020 02:32:53 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:53 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:53 PM : Extracting top 200 daily for 2017-01-15 - us\n",
      "INFO : 10/03/2020 02:32:53 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:53 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:55 PM : Extracting top 200 daily for 2017-01-16 - us\n",
      "INFO : 10/03/2020 02:32:55 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:55 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:56 PM : Extracting top 200 daily for 2017-01-17 - us\n",
      "INFO : 10/03/2020 02:32:56 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:56 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:57 PM : Extracting top 200 daily for 2017-01-18 - us\n",
      "INFO : 10/03/2020 02:32:57 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:57 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:32:59 PM : Extracting top 200 daily for 2017-01-19 - us\n",
      "INFO : 10/03/2020 02:32:59 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:32:59 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:00 PM : Extracting top 200 daily for 2017-01-20 - us\n",
      "INFO : 10/03/2020 02:33:00 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:00 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:02 PM : Extracting top 200 daily for 2017-01-21 - us\n",
      "INFO : 10/03/2020 02:33:02 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:02 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:03 PM : Extracting top 200 daily for 2017-01-22 - us\n",
      "INFO : 10/03/2020 02:33:03 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:03 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:04 PM : Extracting top 200 daily for 2017-01-23 - us\n",
      "INFO : 10/03/2020 02:33:04 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:04 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:05 PM : Extracting top 200 daily for 2017-01-24 - us\n",
      "INFO : 10/03/2020 02:33:05 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:05 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:06 PM : Extracting top 200 daily for 2017-01-25 - us\n",
      "INFO : 10/03/2020 02:33:06 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:06 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:07 PM : Extracting top 200 daily for 2017-01-26 - us\n",
      "INFO : 10/03/2020 02:33:07 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:07 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:08 PM : Extracting top 200 daily for 2017-01-27 - us\n",
      "INFO : 10/03/2020 02:33:08 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:08 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:09 PM : Extracting top 200 daily for 2017-01-28 - us\n",
      "INFO : 10/03/2020 02:33:09 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:09 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:11 PM : Extracting top 200 daily for 2017-01-29 - us\n",
      "INFO : 10/03/2020 02:33:11 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:11 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:12 PM : Extracting top 200 daily for 2017-01-30 - us\n",
      "INFO : 10/03/2020 02:33:12 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:12 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:13 PM : Extracting top 200 daily for 2017-01-31 - us\n",
      "INFO : 10/03/2020 02:33:13 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:13 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:15 PM : Extracting top 200 daily for 2017-02-01 - us\n",
      "INFO : 10/03/2020 02:33:15 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:15 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:15 PM : Extracting top 200 daily for 2017-02-02 - us\n",
      "INFO : 10/03/2020 02:33:15 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:16 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:17 PM : Extracting top 200 daily for 2017-02-03 - us\n",
      "INFO : 10/03/2020 02:33:17 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:17 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:17 PM : Extracting top 200 daily for 2017-02-04 - us\n",
      "INFO : 10/03/2020 02:33:17 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:17 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:19 PM : Extracting top 200 daily for 2017-02-05 - us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 10/03/2020 02:33:19 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:19 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:20 PM : Extracting top 200 daily for 2017-02-06 - us\n",
      "INFO : 10/03/2020 02:33:20 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:20 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:21 PM : Extracting top 200 daily for 2017-02-07 - us\n",
      "INFO : 10/03/2020 02:33:21 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:21 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:22 PM : Extracting top 200 daily for 2017-02-08 - us\n",
      "INFO : 10/03/2020 02:33:22 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:22 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:23 PM : Extracting top 200 daily for 2017-02-09 - us\n",
      "INFO : 10/03/2020 02:33:23 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:23 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:25 PM : Extracting top 200 daily for 2017-02-10 - us\n",
      "INFO : 10/03/2020 02:33:25 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:25 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:26 PM : Extracting top 200 daily for 2017-02-11 - us\n",
      "INFO : 10/03/2020 02:33:26 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:26 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:27 PM : Extracting top 200 daily for 2017-02-12 - us\n",
      "INFO : 10/03/2020 02:33:27 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:27 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:28 PM : Extracting top 200 daily for 2017-02-13 - us\n",
      "INFO : 10/03/2020 02:33:28 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:28 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:29 PM : Extracting top 200 daily for 2017-02-14 - us\n",
      "INFO : 10/03/2020 02:33:29 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:29 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:31 PM : Extracting top 200 daily for 2017-02-15 - us\n",
      "INFO : 10/03/2020 02:33:31 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:31 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:32 PM : Extracting top 200 daily for 2017-02-16 - us\n",
      "INFO : 10/03/2020 02:33:32 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:32 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:34 PM : Extracting top 200 daily for 2017-02-17 - us\n",
      "INFO : 10/03/2020 02:33:34 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:34 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:35 PM : Extracting top 200 daily for 2017-02-18 - us\n",
      "INFO : 10/03/2020 02:33:35 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:35 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:36 PM : Extracting top 200 daily for 2017-02-19 - us\n",
      "INFO : 10/03/2020 02:33:36 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:36 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:37 PM : Extracting top 200 daily for 2017-02-20 - us\n",
      "INFO : 10/03/2020 02:33:37 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:37 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:38 PM : Extracting top 200 daily for 2017-02-21 - us\n",
      "INFO : 10/03/2020 02:33:38 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:38 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:39 PM : Extracting top 200 daily for 2017-02-22 - us\n",
      "INFO : 10/03/2020 02:33:39 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:39 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:40 PM : Extracting top 200 daily for 2017-02-23 - us\n",
      "INFO : 10/03/2020 02:33:40 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:40 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:41 PM : Extracting top 200 daily for 2017-02-24 - us\n",
      "INFO : 10/03/2020 02:33:41 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:41 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:42 PM : Extracting top 200 daily for 2017-02-25 - us\n",
      "INFO : 10/03/2020 02:33:42 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:42 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:43 PM : Extracting top 200 daily for 2017-02-26 - us\n",
      "INFO : 10/03/2020 02:33:43 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:43 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:44 PM : Extracting top 200 daily for 2017-02-27 - us\n",
      "INFO : 10/03/2020 02:33:44 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:44 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:45 PM : Extracting top 200 daily for 2017-02-28 - us\n",
      "INFO : 10/03/2020 02:33:45 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:45 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:46 PM : Extracting top 200 daily for 2017-03-01 - us\n",
      "INFO : 10/03/2020 02:33:46 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:46 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:47 PM : Extracting top 200 daily for 2017-03-02 - us\n",
      "INFO : 10/03/2020 02:33:47 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:47 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:48 PM : Extracting top 200 daily for 2017-03-03 - us\n",
      "INFO : 10/03/2020 02:33:48 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:48 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:49 PM : Extracting top 200 daily for 2017-03-04 - us\n",
      "INFO : 10/03/2020 02:33:49 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:49 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:50 PM : Extracting top 200 daily for 2017-03-05 - us\n",
      "INFO : 10/03/2020 02:33:50 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:50 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:51 PM : Extracting top 200 daily for 2017-03-06 - us\n",
      "INFO : 10/03/2020 02:33:51 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:51 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:52 PM : Extracting top 200 daily for 2017-03-07 - us\n",
      "INFO : 10/03/2020 02:33:52 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:52 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:53 PM : Extracting top 200 daily for 2017-03-08 - us\n",
      "INFO : 10/03/2020 02:33:53 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:53 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:55 PM : Extracting top 200 daily for 2017-03-09 - us\n",
      "INFO : 10/03/2020 02:33:55 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:55 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:56 PM : Extracting top 200 daily for 2017-03-10 - us\n",
      "INFO : 10/03/2020 02:33:56 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:56 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:57 PM : Extracting top 200 daily for 2017-03-11 - us\n",
      "INFO : 10/03/2020 02:33:57 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:57 PM : Done appending to the file top_200_daily.csv!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 10/03/2020 02:33:58 PM : Extracting top 200 daily for 2017-03-12 - us\n",
      "INFO : 10/03/2020 02:33:58 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:58 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:33:59 PM : Extracting top 200 daily for 2017-03-13 - us\n",
      "INFO : 10/03/2020 02:33:59 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:33:59 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:00 PM : Extracting top 200 daily for 2017-03-14 - us\n",
      "INFO : 10/03/2020 02:34:00 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:00 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:02 PM : Extracting top 200 daily for 2017-03-15 - us\n",
      "INFO : 10/03/2020 02:34:02 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:02 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:03 PM : Extracting top 200 daily for 2017-03-16 - us\n",
      "INFO : 10/03/2020 02:34:03 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:03 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:05 PM : Extracting top 200 daily for 2017-03-17 - us\n",
      "INFO : 10/03/2020 02:34:05 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:05 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:06 PM : Extracting top 200 daily for 2017-03-18 - us\n",
      "INFO : 10/03/2020 02:34:06 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:06 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:07 PM : Extracting top 200 daily for 2017-03-19 - us\n",
      "INFO : 10/03/2020 02:34:07 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:07 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:09 PM : Extracting top 200 daily for 2017-03-20 - us\n",
      "INFO : 10/03/2020 02:34:09 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:09 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:10 PM : Extracting top 200 daily for 2017-03-21 - us\n",
      "INFO : 10/03/2020 02:34:10 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:10 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:11 PM : Extracting top 200 daily for 2017-03-22 - us\n",
      "INFO : 10/03/2020 02:34:11 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:11 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:12 PM : Extracting top 200 daily for 2017-03-23 - us\n",
      "INFO : 10/03/2020 02:34:12 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:12 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:13 PM : Extracting top 200 daily for 2017-03-24 - us\n",
      "INFO : 10/03/2020 02:34:13 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:13 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:15 PM : Extracting top 200 daily for 2017-03-25 - us\n",
      "INFO : 10/03/2020 02:34:15 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:15 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:16 PM : Extracting top 200 daily for 2017-03-26 - us\n",
      "INFO : 10/03/2020 02:34:16 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:16 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:17 PM : Extracting top 200 daily for 2017-03-27 - us\n",
      "INFO : 10/03/2020 02:34:17 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:17 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:18 PM : Extracting top 200 daily for 2017-03-28 - us\n",
      "INFO : 10/03/2020 02:34:18 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:18 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:19 PM : Extracting top 200 daily for 2017-03-29 - us\n",
      "INFO : 10/03/2020 02:34:19 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:19 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:21 PM : Extracting top 200 daily for 2017-03-30 - us\n",
      "INFO : 10/03/2020 02:34:21 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:21 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:22 PM : Extracting top 200 daily for 2017-03-31 - us\n",
      "INFO : 10/03/2020 02:34:22 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:22 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:23 PM : Extracting top 200 daily for 2017-04-01 - us\n",
      "INFO : 10/03/2020 02:34:23 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:23 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:24 PM : Extracting top 200 daily for 2017-04-02 - us\n",
      "INFO : 10/03/2020 02:34:24 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:24 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:25 PM : Extracting top 200 daily for 2017-04-03 - us\n",
      "INFO : 10/03/2020 02:34:25 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:25 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:26 PM : Extracting top 200 daily for 2017-04-04 - us\n",
      "INFO : 10/03/2020 02:34:26 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:26 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:27 PM : Extracting top 200 daily for 2017-04-05 - us\n",
      "INFO : 10/03/2020 02:34:27 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:27 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:28 PM : Extracting top 200 daily for 2017-04-06 - us\n",
      "INFO : 10/03/2020 02:34:28 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:28 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:30 PM : Extracting top 200 daily for 2017-04-07 - us\n",
      "INFO : 10/03/2020 02:34:30 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:30 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:31 PM : Extracting top 200 daily for 2017-04-08 - us\n",
      "INFO : 10/03/2020 02:34:31 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:31 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:32 PM : Extracting top 200 daily for 2017-04-09 - us\n",
      "INFO : 10/03/2020 02:34:32 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:32 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:34 PM : Extracting top 200 daily for 2017-04-10 - us\n",
      "INFO : 10/03/2020 02:34:34 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:34 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:35 PM : Extracting top 200 daily for 2017-04-11 - us\n",
      "INFO : 10/03/2020 02:34:35 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:35 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:37 PM : Extracting top 200 daily for 2017-04-12 - us\n",
      "INFO : 10/03/2020 02:34:37 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:37 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:38 PM : Extracting top 200 daily for 2017-04-13 - us\n",
      "INFO : 10/03/2020 02:34:38 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:38 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:39 PM : Extracting top 200 daily for 2017-04-14 - us\n",
      "INFO : 10/03/2020 02:34:39 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:39 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:40 PM : Extracting top 200 daily for 2017-04-15 - us\n",
      "INFO : 10/03/2020 02:34:40 PM : Appending data to the file top_200_daily.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 10/03/2020 02:34:40 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:42 PM : Extracting top 200 daily for 2017-04-16 - us\n",
      "INFO : 10/03/2020 02:34:42 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:42 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:42 PM : Extracting top 200 daily for 2017-04-17 - us\n",
      "INFO : 10/03/2020 02:34:42 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:42 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:44 PM : Extracting top 200 daily for 2017-04-18 - us\n",
      "INFO : 10/03/2020 02:34:44 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:44 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:45 PM : Extracting top 200 daily for 2017-04-19 - us\n",
      "INFO : 10/03/2020 02:34:45 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:45 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:46 PM : Extracting top 200 daily for 2017-04-20 - us\n",
      "INFO : 10/03/2020 02:34:46 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:46 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:47 PM : Extracting top 200 daily for 2017-04-21 - us\n",
      "INFO : 10/03/2020 02:34:47 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:47 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:48 PM : Extracting top 200 daily for 2017-04-22 - us\n",
      "INFO : 10/03/2020 02:34:48 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:48 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:50 PM : Extracting top 200 daily for 2017-04-23 - us\n",
      "INFO : 10/03/2020 02:34:50 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:50 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:51 PM : Extracting top 200 daily for 2017-04-24 - us\n",
      "INFO : 10/03/2020 02:34:51 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:51 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:52 PM : Extracting top 200 daily for 2017-04-25 - us\n",
      "INFO : 10/03/2020 02:34:52 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:52 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:53 PM : Extracting top 200 daily for 2017-04-26 - us\n",
      "INFO : 10/03/2020 02:34:53 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:53 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:55 PM : Extracting top 200 daily for 2017-04-27 - us\n",
      "INFO : 10/03/2020 02:34:55 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:55 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:57 PM : Extracting top 200 daily for 2017-04-28 - us\n",
      "INFO : 10/03/2020 02:34:57 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:57 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:57 PM : Extracting top 200 daily for 2017-04-29 - us\n",
      "INFO : 10/03/2020 02:34:57 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:57 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:58 PM : Extracting top 200 daily for 2017-04-30 - us\n",
      "INFO : 10/03/2020 02:34:58 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:58 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:34:59 PM : Extracting top 200 daily for 2017-05-01 - us\n",
      "INFO : 10/03/2020 02:34:59 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:34:59 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:00 PM : Extracting top 200 daily for 2017-05-02 - us\n",
      "INFO : 10/03/2020 02:35:00 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:00 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:02 PM : Extracting top 200 daily for 2017-05-03 - us\n",
      "INFO : 10/03/2020 02:35:02 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:02 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:03 PM : Extracting top 200 daily for 2017-05-04 - us\n",
      "INFO : 10/03/2020 02:35:03 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:03 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:04 PM : Extracting top 200 daily for 2017-05-05 - us\n",
      "INFO : 10/03/2020 02:35:04 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:04 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:05 PM : Extracting top 200 daily for 2017-05-06 - us\n",
      "INFO : 10/03/2020 02:35:05 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:05 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:06 PM : Extracting top 200 daily for 2017-05-07 - us\n",
      "INFO : 10/03/2020 02:35:06 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:06 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:08 PM : Extracting top 200 daily for 2017-05-08 - us\n",
      "INFO : 10/03/2020 02:35:08 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:08 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:09 PM : Extracting top 200 daily for 2017-05-09 - us\n",
      "INFO : 10/03/2020 02:35:09 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:09 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:09 PM : Extracting top 200 daily for 2017-05-10 - us\n",
      "INFO : 10/03/2020 02:35:09 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:09 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:10 PM : Extracting top 200 daily for 2017-05-11 - us\n",
      "INFO : 10/03/2020 02:35:10 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:10 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:12 PM : Extracting top 200 daily for 2017-05-12 - us\n",
      "INFO : 10/03/2020 02:35:12 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:12 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:13 PM : Extracting top 200 daily for 2017-05-13 - us\n",
      "INFO : 10/03/2020 02:35:13 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:13 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:14 PM : Extracting top 200 daily for 2017-05-14 - us\n",
      "INFO : 10/03/2020 02:35:14 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:14 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:15 PM : Extracting top 200 daily for 2017-05-15 - us\n",
      "INFO : 10/03/2020 02:35:15 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:15 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:16 PM : Extracting top 200 daily for 2017-05-16 - us\n",
      "INFO : 10/03/2020 02:35:16 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:16 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:17 PM : Extracting top 200 daily for 2017-05-17 - us\n",
      "INFO : 10/03/2020 02:35:17 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:17 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:18 PM : Extracting top 200 daily for 2017-05-18 - us\n",
      "INFO : 10/03/2020 02:35:18 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:18 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:20 PM : Extracting top 200 daily for 2017-05-19 - us\n",
      "INFO : 10/03/2020 02:35:20 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:20 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:21 PM : Extracting top 200 daily for 2017-05-20 - us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO : 10/03/2020 02:35:21 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:21 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:22 PM : Extracting top 200 daily for 2017-05-21 - us\n",
      "INFO : 10/03/2020 02:35:22 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:22 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:23 PM : Extracting top 200 daily for 2017-05-22 - us\n",
      "INFO : 10/03/2020 02:35:23 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:23 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:24 PM : Extracting top 200 daily for 2017-05-23 - us\n",
      "INFO : 10/03/2020 02:35:24 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:24 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:25 PM : Extracting top 200 daily for 2017-05-24 - us\n",
      "INFO : 10/03/2020 02:35:25 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:25 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:26 PM : Extracting top 200 daily for 2017-05-25 - us\n",
      "INFO : 10/03/2020 02:35:26 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:26 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:27 PM : Extracting top 200 daily for 2017-05-26 - us\n",
      "INFO : 10/03/2020 02:35:27 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:27 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:29 PM : Extracting top 200 daily for 2017-05-27 - us\n",
      "INFO : 10/03/2020 02:35:29 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:29 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:30 PM : Extracting top 200 daily for 2017-05-28 - us\n",
      "INFO : 10/03/2020 02:35:30 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:30 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:31 PM : Extracting top 200 daily for 2017-05-29 - us\n",
      "INFO : 10/03/2020 02:35:31 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:31 PM : Done appending to the file top_200_daily.csv!!!\n",
      "INFO : 10/03/2020 02:35:32 PM : Extracting top 200 daily for 2017-05-30 - us\n",
      "INFO : 10/03/2020 02:35:32 PM : Appending data to the file top_200_daily.csv...\n",
      "INFO : 10/03/2020 02:35:32 PM : Done appending to the file top_200_daily.csv!!!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-be24ed4e439d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpotifyCharts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop200Daily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"top_200_daily.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"us\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fycharts/SpotifyCharts.py\u001b[0m in \u001b[0;36mtop200Daily\u001b[0;34m(self, output_file, output_db, webhook, start, end, region)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mregions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhelperTop200Daily\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheRange\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                                         \u001b[0mdict_for_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"df\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_file\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"j\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fycharts/crawler_base.py\u001b[0m in \u001b[0;36mhelperTop200Daily\u001b[0;34m(self, date, region)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Extracting top 200 daily for {} - {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://spotifycharts.com/regional/{}/daily/{}/download\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__makeRequests\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fycharts/crawler_base.py\u001b[0m in \u001b[0;36m__makeRequests\u001b[0;34m(self, url, date, region, isSkip, size)\u001b[0m\n\u001b[1;32m     72\u001b[0m                                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                                 \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTTPAdapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_retries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GET'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    729\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                 \u001b[0mrelease_conn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelease_conn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                 body_pos=body_pos, **response_kw)\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mdrain_and_release_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m             \u001b[0mretries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Retry: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             return self.urlopen(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    280\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sleep_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_connection_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36m_sleep_backoff\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbackoff\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackoff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "api = SpotifyCharts()\n",
    "api.top200Daily(output_file = \"top_200_daily.csv\", region = [\"us\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
